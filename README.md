# Collaborative Visual Storytelling with TABAN – Supplementary Materials

This repository contains materials and documentation related to the **collaborative visual storytelling** project involving both human-human and human-robot interactions.

## 📁 Folder Descriptions

### 📂 `Announcing_Turns_Pictures`
Images used by the robot to announce whose turn it was during storytelling sessions. These visual cues helped manage the turn-taking mechanism.

### 📂 `Dataset_Images`
A collection of images shown to participants (both children and the robot) to inspire story generation. These visuals served as prompts for collaborative storytelling.

### 📂 `Models_Output_Sample`
Contains a PDF file presenting a sample of user input and model-generated outputs during storytelling. Demonstrates how the LLM and VLM were used to co-create stories.

### 📂 `Persian_Translated_Questionnaires`
Persian versions of the questionnaires used after each storytelling activity. These were designed to evaluate children's experiences and their acceptance of the robot.

### 📂 `Pictures`
Photos capturing the storytelling environment, including the robot setup, interaction space, and children's engagement during the sessions.

### 📂 `Prompts`
Includes a PDF file listing the prompts provided to both the **Large Language Model (LLM)** and **Vision-Language Model (VLM)** to generate relevant story content from images and user input.

### 🎥 `Watch the Robot in Action`
A short video showing the collaborative storytelling interaction between a child and TABAN.
https://youtu.be/1VvhRrw_ynw

