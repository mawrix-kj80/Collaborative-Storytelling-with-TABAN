# Collaborative Visual Storytelling with TABAN â€“ Supplementary Materials

This repository contains materials and documentation related to the **collaborative visual storytelling** project involving both human-human and human-robot interactions.

## ğŸ“ Folder Descriptions

### ğŸ“‚ `Announcing_Turns_Pictures`
Images used by the robot to announce whose turn it was during storytelling sessions. These visual cues helped manage the turn-taking mechanism.

### ğŸ“‚ `Dataset_Images`
A collection of images shown to participants (both children and the robot) to inspire story generation. These visuals served as prompts for collaborative storytelling.

### ğŸ“‚ `Models_Output_Sample`
Contains a PDF file presenting a sample of user input and model-generated outputs during storytelling. Demonstrates how the LLM and VLM were used to co-create stories.

### ğŸ“‚ `Persian_Translated_Questionnaires`
Persian versions of the questionnaires used after each storytelling activity. These were designed to evaluate children's experiences and their acceptance of the robot.

### ğŸ“‚ `Pictures`
Photos capturing the storytelling environment, including the robot setup, interaction space, and children's engagement during the sessions.

### ğŸ“‚ `Prompts`
Includes a PDF file listing the prompts provided to both the **Large Language Model (LLM)** and **Vision-Language Model (VLM)** to generate relevant story content from images and user input.

### ğŸ¥ `Watch the Robot in Action`
A short video showing the collaborative storytelling interaction between a child and TABAN.
https://youtu.be/1VvhRrw_ynw

